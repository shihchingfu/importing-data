---
title: "Importing data in R"
author: "Shih Ching Fu"
date: "March 2020"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: 
      collapsed: true
      smooth_scroll: true
    number_sections: true
    theme: readable
    highlight: haddock
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,tidy = TRUE, paged.print = TRUE )
```

# Summary

This is a brief guide to importing various data file formats into `R`.

The file formats covered here are:

- Plain-text files (`.CSV`, `.TSV`)
- Microsoft Excel spreadsheets (`.XLSX`)
- Google Sheets
- SPSS, STATA, and SAS data files (`.SAV`, `.DTA`, `.SAS7BDAT`)

The following `R` packages are used in this guide:

- `readr`[^readr]
- `data.table`[^data.table]
- `readxl`[^readxl]
- `googlesheets4`[^googlesheets4]
- `haven`[^haven]

[^readr]: [`readr`](https://readr.tidyverse.org/) package
[^data.table]: [`data.table`](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html) package
[^readxl]: [`readxl`](https://readxl.tidyverse.org/) package
[^googlesheets4]: [`googlesheets4`](https://googlesheets4.tidyverse.org/) package
[^haven]: [`haven`](https://haven.tidyverse.org/) package

These can be installed using the `install.packages()` command:

```{r eval=FALSE}
install.packages("readr")
install.packages("data.table")
install.packages("readxl")
install.packages("googlesheets4")
install.packages("haven")
```

## Data frames

Data in `R` are typically stored as *data frames* where values are arranged into rows and columns akin to a table. Below are the first ten rows of the example `iris`[^iris] data frame that comes packaged with `R`:

[^iris]: Anderson, Edgar (1935). The irises of the Gaspe Peninsula, *Bulletin of the American Iris Society*, **59**, 2â€“5


```{r echo=FALSE}
head(iris, n = 10)
```

Data frames have a number of characteristics worth mentioning:

- Each column of a data frame constitutes a *vector* and like all vectors in `R` must contain only a single data type, e.g., numeric, factor, logical, character, etc.
- Each column however may store a different data type from other columns.
- Each column is named and can be accessed by that name using dollar sign (`$`) notation. For example, `iris$Sepal.Width` returns the `Sepal.Width` column of the `iris` data frame as a vector.
- Almost all `R` functions are built to accept data frames as input.

In the following examples, data is imported into `R` as data frames.

## Tidy data

Before going further it is worth considering the arrangement of the values in your dataset as you import it. By this we mean what do the rows and columns of your dataset represent? In particular, we'd like to commend to you the so-called ***tidy*** data format.

Tidy data is tabular data that is organised such that:

1. each observation has its own row,
2. each variable has its own column, and
3. each value has its own cell.

This is sometimes referred to tall or long form data because of its shape. By contrast you may have 'wide' data where, for example, columns are measurements of the *same* variable but taken at different time points. Both are valid ways to store data but we'd argue that tidy data is easier to manipulate. This is the philosophy behind the omnibus of `R` packages that constitute the `tidyverse` bundle of `R` packages.

We will see some examples of both kinds of data but the `R` commands for transforming between these  is best covered in a separate tutorial.

## Data used in this guide

The dataset used in this guide comes from *Exploring Longitudinal Data on Change*[^eldc] by Judith D. Singer and John B. Willett (2003). It comprises survey data assessing the tolerance of teenage participants towards various deviant behaviours (!).

[^eldc]: Judith D. Singer, John B. Willett (2003), Exploring Longitudinal Data on Change, DOI: [10.1093/acprof:oso/9780195152968.003.0002](https://doi.org/10.1093/acprof:oso/9780195152968.003.0002)


# Plain-text files

Plain-text files are human-readable once opened in a simple text editor. The most commonly encounted plain-text data files are comma separated values or tab separated values, CSV and TSV respectively. These are highly portable and often the *de facto* file format for sharing datasets. 

The `readr` package has three useful functions for reading plain-text data files:

1. `read_csv()`
2. `read_tsv()`
3. `read_delim()`

```{r}
library(readr)
```

```{r}
# Read comma separated value (CSV) file
tol_csv <- read_csv("data/tolerance.csv")
```

Notice that `read_csv()` and indeed all the `read_` functions below print out the data types it has detected for each column. In this instance they are all `double`s or double precision floating point numbers, i.e., real numbers on the number line.

```{r}
# Print out the first six rows of the data frame
head(tol_csv)
```

It would be worth doing some wrangling to correct some of the data types. For example, `id`, `male`, and `time` are more sensibly treated as categorical variables or `factor`s in `R`.

```{r}
# Read tab separated value (TSV) file
tol_tsv <- read_tsv("data/tolerance.tsv")
head(tol_tsv)
```

```{r}
# Read a text file delimited by carets
tol_delim <- read_delim("data/tolerance_pp.txt", delim = "$")
head(tol_delim, n = 10)
```

Notice that of the three datasets imported above, only the third (`tol_delim`) is in *tidy* format. The first two data frames have information stored in both their cells and their headers. For example, the column label `TOL11` stands for tolerance value taken at age 11; two variables tolerance and time point. In contrast, the tidy data frame splits out values for each time point into distinct rows and adds an extra column for the time.

## `data.table` package

An alternative function for importing plain-text data files is `fread()` in the `data.table` package. It is extremely fast and powerful and can often identify the delimiter character automatically. Because of its speed it's highly recommended for reading in very large data files.

```{r}
library(data.table)
tol_dt <- fread(file = "data/tolerance.tsv")
head(tol_dt)
```

# Microsoft Excel

In some disciplines Microsoft Excel spreadsheets have become the standard file format to store and process data. However, more complex analyses are available in `R` so it may be worthwhile switching over.

The `readxl` package contains the function `read_excel()` for reading in .XLS or .XLSX files.

```{r}
library(readxl)
tol_xlsx <- read_excel("data/tolerances.xlsx")
head(tol_xlsx)
```

However, one distinction between Excel spreadsheets and 'flat' plain-text files is that the former may comprise several worksheets. To see the worksheets in an Excel spreadsheet use the `excel_sheets()` function.

```{r}
excel_sheets("data/tolerances.xlsx")
```

By default the `read_excel()` function reads the first worksheet in the .XLSX file. The `sheet = ` argument specifies which worksheet to import.

```{r cache=TRUE}
tol_xlsx2 <- read_excel("data/tolerances.xlsx", sheet = "tolerance_pp")
head(tol_xlsx2)
```


# Google Sheets

One convenient way to store and share (non-sensitve) data is using Google Sheets. The package `googlesheets4` is built for downloading online Google Sheets into local data frames, including the handling of Google authentication and sign-in.

```{r}
library(googlesheets4)
```

The `sheets_get()` function retrieves metadata about a Google Sheet.

```{r}
# URL to the gapminder Google Sheet.
url <- "https://docs.google.com/spreadsheets/d/1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077"
sheets_deauth()
sheets_get(url)
```

Knowing the names of the worksheets we can import them by name or number using `sheets_read()`.

```{r}
# 4th worksheet of the gapminder Google Sheet corresponds to European data
gapminder_eu <- sheets_read(url, sheet = 4)
head(gapminder_eu)
```

# Statistical Software

The `haven` package has functions to import SPSS, SAS, and STATA files.

```{r}
library(haven)
```

Use `read_sav()` or `read_spss()` to import SPSS `.SAV` files.

```{r}
# SPSS
tol_sav <- read_sav("data/tolerance.sav")
head(tol_sav)
```

Use `read_sas()` to import SAS `.SAS7BDAT` files.

```{r}
# SAS
tol_sas <- read_sas("data/tolerance.sas7bdat")
head(tol_sas)
```

Use `read_dta()` or `read_stata()` to import STATA `.DTA` files.

```{r}
# STATA
tol_dta <- read_dta("data/tolerance.dta")
head(tol_dta)
```


# More!

This guide has only covered a few of the data formats that `R` can accommodate. Other common sources of data include SQL databases, cloud-based APIs, and even scraping directly from webpages. Take a look at the 'R Data Import/Export'[^rdie] manual for a broader summary of what's available.



[^rdie]: [R Data Import/Export](https://cran.r-project.org/doc/manuals/r-release/R-data.html) manual


